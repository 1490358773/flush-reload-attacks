\documentclass{acm_proc_article-sp}

\usepackage{url}
\usepackage{microtype}

\begin{document}

% Without this, stuff overfills into the margin. TODO: Eventually, rewrite those
% paragraphs so that they don't.
\sloppy

\title{Side Channel Attacks Against Non-Cryptographic Applications\titlenote{Submitted January 22, 2015}}
\subtitle{CPSC 502.04 Project Interim Report}

\numberofauthors{1}

\author{
\alignauthor
Taylor Hornby (Supervised by Dr. John Aycock)\titlenote{John Aycock reviewed and
edited a draft of this document before it was submitted.}\\
\email{th@defuse.ca}
}

\maketitle

\begin{abstract}
Side channel attacks are almost always applied to cryptography-related software
and hardware, so we ask whether significant side-channel vulnerabilities exist
in non-cryptographic systems. In this Interim report, we discuss evidence that
the FLUSH+RELOAD side channel attack can be successfully applied to
non-cryptographic software. In particular, we show how to distinguish between
hidden and normal TrueCrypt volumes, and to see which of the top 100 most
visited Wikipedia pages the victim is visiting using the Links web browser.
Finally, we lay out the next steps for the project, including a way to build the
attacks automatically.
\end{abstract}

\section{Introduction}
\label{sec:attacks}

Computers are physical realizations of abstract machines. Therefore, when we
program computers, it is easiest to think abstractly. Systems are organized into
layers of abstraction with the highest-level ideas and operations at the top,
the bits and bytes further down, and the physical implementation \textendash\
wires and the voltages on them \textendash\ still further down.

Complexity is hidden behind interfaces and APIs. We can use lower layers without
having to understand their inner workings. Conversely, we can write libraries
without having to consider and understand all of the possible uses.

Thinking about computers this way makes them manageable. Without abstraction, it
is impossible to remember all of the details. When the details are divided into
parts with clear boundaries, we can remember how each part is \emph{to be used},
without having to know how each part \emph{works}.

The divisions are not always perfect, and this often leads to security problems.
APIs are often misused and assumptions are often made about the internal
workings of a different part. An interesting boundary is the one between the
computer as an abstract machine, and the computer as a physical machine.

When we think about computers as abstract machines, it is natural to think in
terms of explicit communication paths. After all, the explicit communication
channels are the ones that matter: reading input and writing output. The user
does not care exactly how much power their computer is using, how much noise it
makes, or how long it takes to perform an operation, so long as the behavior
stays within reasonable bounds. Thinking physically, things are different. These
values all represent information about what is going on inside the computer.
Measurable variations of these values are called \emph{side channels}
\cite{kelsey1998side}.

Side channels sometimes leak information that is supposed to be kept secret. For
example, research has shown that by taking a close look at the amount of power
used by smart cards, we can steal the closely-guarded RSA secret keys inside
them \cite{messerges1999power}. This is possible because the device performs
a longer operation for key bits that are 1 and a shorter operation for key bits
that are is 0. So by looking at the amount of power it uses over time, it is
possible to tell which bits of the key are 0 and which are 1. Attacks like
these, which use side channels to learn secret information about a system are
called \emph{side channel attacks}. Many examples are known:

\begin{itemize}
\item Genkin et al. \cite{genkin2013rsa} showed that by listening to the sounds
made by a computer performing RSA decryptions, it was possible to extract the
secret key.

\item SSH sends one packet per keystroke, immediately after the key is pressed.
Song et al. \cite{song2001timing} showed that information about users' passwords
can be inferred from the timing of the packets.

\item There is a lot of research \cite{aciiccmez2006cache, bernstein2005cache,
    osvik2006cache, weiss2012cache} showing that it is very hard to write
    a side-channel-free implementation of the industry-standard AES cipher.

\item Timing side channels were shown to work even remotely across a local
network by Brumley and Boneh \cite{brumley2005remote}.

\item The BREACH attack on SSL \cite{gluck2013breach} uses variations in the
    compressibility of data as a side channel to learn secret tokens embedded in
    an encrypted web page.
\end{itemize}

Side channels present a challenge because a computer program can be logically
correct and still be vulnerable to side channel attacks. A program can respond
to all inputs in all the right ways, always getting the right answer, but still
leak secrets out through the time it takes to run or the amount of power it
uses.

The list above shows how diverse and widespread side channel attacks are.
Despite their prevalence, we still don't understand them very well. The next
section presents some open questions that this project will try to answer.

In this section, we described what side-channel attacks are and why we care
about them. In Section \ref{sec:problem}, we present the research questions that we are
trying to answer. Section \ref{sec:relwork} reviews related work and the
FLUSH+RELOAD attack that our research is built on. Research methodology is
described in Section \ref{sec:methods}. Attacks confirming our hypothesis are
given in \ref{sec:attacks}. Section \ref{sec:future} explains where we
will go from here, and finally Section \ref{sec:conclusion} concludes.

\section{Research Problem}
\label{sec:problem}

In the last section, we saw that side channel attacks are everywhere, and that
they can be devastating for a system's security. In order to build defenses
against side-channel attacks, we have to understand them. Our ignorance about
side channel attacks boils down to two central questions: Under what conditions
are side-channel attacks possible? and when a side-channel vulnerability exists,
how reliably can it be exploited?

Many examples of side-channel attacks have been presented in the literature.
Most research is focused on developing new attack vectors. Acoustic
cryptanalysis \cite{genkin2013rsa} and extracting keys from ground potential
fluctuations \cite{genkin2014get} are recent examples. These new types of attack
are almost universally applied to cryptography. This makes sense, because
leaking a small number of bits (i.e.\ the key) from a cryptographic application
weakens and may completely break its security. To compound the issue,
cryptography makes heavy, repeated, use of the few bits that it does need to
keep secret, making them more likely to influence the side channels.

It makes sense why cryptography is attacked, but it is unclear if this focus on
cryptography is because non-cryptographic programs can not be attacked, or if
cryptography is just the low-hanging fruit that gets attacked first. This is an
important question to resolve, since if non-cryptographic programs \emph{are}
just as vulnerable to side-channels, we might be overlooking serious
vulnerabilities in the programs we use every day. An attack against a regular
program can be just as devastating as an attack against an implementation of
cryptography. For example, if it is possible for one user to spy on another
user's keystrokes as they compose an email, that is just as serious an attack as
if the first user could steal the second user's PGP private key.

This project will try to answer that question. In particular, we ask:

\begin{enumerate}
\item What impact do side-channel attacks have on non-cryptographic systems?

\item Under what conditions are side channels a threat? Under what conditions
      are they not?

\item Does every developer have to be aware of side channels and design their
      code to resist attacks? Or is it enough to care about side channels only
      for sensitive applications like cryptography?

\item Are there automated technological defenses against side-channel attacks?
      Are there easy-to-follow coding guidelines that reduce the impact of side
      channels?

\item Can side channels be used for good? Could we, perhaps, use side channels
      monitoring as a mechanism to spot attacks?
\end{enumerate}

If this project finds that non-cryptographic attacks represent real threats, it
will motivate the research community to widen the scope of their attacks and
defenses. If the result is that side-channels cannot be applied to regular
programs, we can learn \emph{why} not, and begin to apply that knowledge to
build defenses.

We have made progress towards answering these questions. The next section
discusses related work, and after that we lay out some attacks.

\section{Related Work}
\label{sec:relwork}

Our attack demonstrations use the FLUSH+RELOAD attack \cite{yarom2013flush},
which is described in detail in the next section. In the section after that, we
list other related work, including previously-known non-cryptographic
side-channel attacks.

\subsection{The FLUSH+RELOAD Attack}

\textsc{Flush+Reload} \cite{yarom2013flush} is a generic L3 (or last-level)
cache side-channel attack. Taking advantage of executable code page sharing, it
allows one process to spy on the code another process is running.

The attacker first selects a handful of cache lines they want to monitor. When
the attack starts, those cache lines are flushed out of the L3 cache. From then
on, time is divided into slots whose durations are measured in clock cycles. For
example, the original GnuPG attack in \cite{yarom2013flush} uses a slot size of
2048 cycles. At the end of each slot, the target cache lines, called ``probes''
are read. If the read is fast (i.e.\ consistent with being in L3 cache), it is
likely that the victim process executed some code in that cache line in the
slot. If the read is slow, the victim process did not read that cache line in
the slot. After the probes are timed, they are flushed from the cache, and the
next slot begins.

The side-channel was first described by Bangerter et al.\
\cite{gullasch2011cache}. There, it was used on AES lookup tables that were
hard-coded into the binary. Yarom and Falkner realized it could be applied to
code, and used it to extract the secret key from GnuPG \cite{yarom2013flush}.
Since then, it has also been applied to extract private ECDSA keys from OpenSSL
\cite{benger2014ooh}.

\subsection{Other Non-Cryptographic Side Channel Attacks}

Several papers have applied side-channel attacks to non-cryptographic
applications. However, they are all attacks designed around a specific
application. We are more ambitious, aiming to apply a general side-channel
attack (FLUSH+RELOAD) broadly across a wide range of non-cryptographic software.

Demme et al.\ proposed a measure for side-channel information leakage in
\cite{demme2012side}. It is not applicable to our research, since it measures
information leakage by simulating hardware, and is not a measure of information
leakage for actual vulnerabilities.

Malicious web pages can extract browser history through a side-channel attack
\cite{weinberg2011still}. Timing variations from database indexes are enough to
extract indexed records \cite{futoransky2007nd2db}. Variable bit rate encoding
leaks information about encrypted VoIP conversations
\cite{white2011phonotactic}. In an Android app, UI state can be inferred through
side channels in the GUI framework \cite{chen2014peeking}. On Linux, keystroke
timings can be learned by watching the size of a victim process's stack
\cite{zhang2009peeping}. Timing of key strokes also leaks through SSH's
encryption to reveal information about the password \cite{song2001timing}.
A malicious web page can tell if the browser is running in a virtual machine
(i.e.\ for malware analysis) with JavaScript side-channels \cite{ho2014tick}.
A victim's Internet traffic volume and even individual packet times can be
learned by exploiting side channels in router scheduling algorithms
\cite{kadloor2010low}. Accelerometers in smart phones leak information about the
passwords users type \cite{owusu2012accessory} \cite{cai2012practicality}. Cache
side channels used against the Windows or Linux kernels break kernel space ASLR
\cite{hund2013practical}. A server's power use patterns give away which virtual
machines are running on it \cite{hlavacs2011energy}. It is possible to recover
text from the sounds dot-matrix printers make \cite{backes2010acoustic}.
Differences in the ways web applications interact with the server leak
information about the user's input \cite{bortz2007exposing} \cite{chen2010side}.
The CRIME \cite{duong2012crime} and BREACH \cite{gluck2013breach} attacks use
compression-ratio variations to learn things about the plaintext.

With the exception of the web application attacks (\cite{bortz2007exposing} and
\cite{chen2014peeking}) all of these attacks are very application-specific. Our
contribution is to show that one type of attack (FLUSH+RELOAD) can be easily
applied to lots of different programs.

\section{Methods}
\label{sec:methods}


By exhibiting attacks, we show that FLUSH+RELOAD can be used against
non-cryptographic software to breach the user's privacy. For each software, we
find a feature where private information about the user's activities may be
leaked. With the feature identified, we manually review the program's code and
find the best locations in memory to place FLUSH+RELOAD probes for maximum
information leakage.

Attacks are implemented with the following tools:

\begin{itemize}
    \item A FLUSH+RELOAD attack tool, written in C, takes a binary and probe
        addresses with single-character names as arguments. When probes are hit,
        their single-character names are printed to standard output, with pipe
        characters separating the slots. This tool is a re-implementation of the
        attack tool the original paper's (\cite{yarom2013flush}) authors
        provided us.

    \item A Ruby class that lets Ruby scripts to call the attack tool and
        monitor its output. It augments the attack tool by letting the user get
        a callback whenever there is a ``burst'' of probe hits. This lets the
        attack script react to events (such as the entire execution of
        a command) without having to continually parse the attack tool's output.

    \item Ruby attack scripts are written for each attack, using the interface
        class described above.
\end{itemize}

Experiments are run to determine how accurate the attack tool is at
reconstructing the desired information. All experiments are implemented in code,
so that they are easily repeatable. To facilitate reproduction, all code and raw
experiment data will be published on the Web. 

To avoid confirmation bias, the experiment framework enforces the following
property: the experimenter must decide whether the results are to be saved
before the experiment is run. For example, if the experimenter is doing a test
run, to check the correctness of the experiment code, they cannot save those
results if they happen to confirm the hypothesis. On the other hand, the
experimenter cannot get rid of non-test runs that show negative results. Of
course, it is possible to bypass these measures, but it is impossible to do so
accidentally: you have to manually move or delete a folder, which should never
need to be done if the experimenter is being honest.

Experiments are performed with an Intel Core2 Duo P8700 2.53GHz CPU inside an
ASUS G51 laptop. For cache, it has a split 64kB L1 cache, a unified 3MB L2
cache, and no L3 cache. Unless otherwise stated, all experiments are run with
low system load (at most a few terminals and text editor windows open).

Binaries of attacked programs are built from source and symbols are not
stripped, to make it easier for the experimenter to find probe locations.
Symbols are not required for the attack to work, but without them, finding the
probe locations manually would take longer.

\section{Results}
\label{sec:results}

We present two attacks. The first attack lets an attacking user tell whether
a victim user's TrueCrypt volume is standard or hidden. The second lets the
attacking user tell which of the top 100 Wikipedia pages the victim user visited
using the Links web browser.

\subsection{TrueCrypt}

TrueCrypt is disk encryption software that supports storing encrypted
filesystems (called ``volumes'') in files. TrueCrypt has a ``hidden volume''
feature, which hides a secret volume inside a normal volume one to provide
plausible deniability. The idea is that it is impossible to tell whether
a hidden volume exists, so law enforcement (in some countries) could not legally
force the user to disclose the password.

TrueCrypt has two classes representing the layout of version-two hidden and
normal volumes: \texttt{VolumeLayoutV2Normal} and \texttt{VolumeLayoutV2Hidden}.
Both of these classes implement the \texttt{VolumeLayout} interface. There are
three other classes for different kinds of layouts, but they are not relevant to
this attack. 

When TrueCrypt mounts a volume, it creates instances of all five
\texttt{VolumeLayout} classes and tries to decrypt the volume with each until
the decryption is successful. This is necessary, since to preserve plausible
deniability, there must be no other way to tell which type of volume it is. In
particular, for this attack, we note that \texttt{VolumeLayoutV2Hidden} is tried
first, before \texttt{VolumeLayoutV2Normal}.

The \texttt{VolumeLayout} interface includes a \texttt{GetDataSize()} method,
which all subclasses must implement. This method is only called after the
decryption is successful. Therefore, we can place FLUSH+RELOAD probes as
follows:

\begin{enumerate}
    \item On \texttt{VolumeLayoutV2Normal::GetDataSize}.
    \item On the entrypoint to the TrueCrypt binary.
\end{enumerate}

We tried placing probes on \texttt{VolumeLayoutV2Normal::GetDataSize} and
\texttt{VolumeLayoutV2Hidden::GetDataSize}. This does not work, since, in the
binary, the normal implementation is in the cache line immediately before the
cache line containing the hidden implementation. Our test CPU seems to prefetch
the hidden implementation when the normal one is executed, so there is no way to
tell the difference.

Instead, since \texttt{VolumeLayoutV2Hidden} is tried first, the attack works as
follows:

\begin{itemize}
    \item Capture the spy output when a TrueCrypt volume is mounted via the
          command-line.
      \item If the burst of probe hits ends in the one at
          \texttt{VolumeLayoutV2Normal::GetDataSize}, then the volume is normal.
          Otherwise, the volume is hidden.
\end{itemize}

We implemented the attack in an experiment, which does the following:

\begin{enumerate}
    \item Create two 1,000,000-byte TrueCrypt volumes. One of which is normal,
        the other hidden. Both having the same password.
    \item Repeat the following $S$ times:
        \begin{enumerate}
            \item Dismount both volumes, to ensure neither of them is mounted.
            \item Start the attack tool running on the TrueCrypt binary.
            \item Randomly mount either the normal or hidden volume with
                  TrueCrypt's command-line interface.
            \item Stop the attack tool and retrieve its output.
            \item Decide whether the volume was hidden or normal by checking if
                the output string ends in the
                \texttt{VolumeLayoutV2Normal::GetDataSize} probe. If so, the
                volume is normal. If not, the volume is hidden.
            \item Check if the decision made is correct.
        \end{enumerate}
\end{enumerate}

In one run of the experiment with $S=500$, the decision is correct 416 times
(83\% of the time). In a later run with $S=100$, the decision was correct 97
times (97\% of the time).

So far, we have only tried this attack using TrueCrypt's command-line interface,
and the attacker has to know that the user ran TrueCrypt to mount a volume (and
not some other task, like dismounting a volume). Most TrueCrypt users use the
graphical interface. We believe this attack can be extended to work with the
graphical interface (which uses the same volume mounting code), and to detect
when a volume is being mounted (by placing a third probe on volume-mounting
code).

\subsection{Links Web Browser}

Links is a command-line web browser. By probing the HTML parsing code, we can
determine which of the top 100 Wikipedia pages the user is visiting. We found
good probe locations by trial and error. They are:

\begin{enumerate}
    \item At the top of the \texttt{parse\_html()} function, which begins the
        process of parsing the downloaded HTML.
    \item At the top of \texttt{html\_stack\_dup()}, which duplicates the element
        at the top of a stack used while parsing various HTML tags.
    \item On \texttt{html\_h()}, the function that parses HTML header tags (h1,
        h2, h3...).
    \item On \texttt{html\_span()}, the function that parses HTML span tags.
\end{enumerate}

To chose the probe locations, we aimed for significant parts of the parsing code
that were far enough away from each other to minimize noise in the measurements
(e.g. due to the CPU prefetching code it won't actually execute).

With these probes selected, the attack uses machine learning to determine which
of the top 100 Wikipedia pages were visited. The attack is divided into three
phases: (1) Training, (2) Victim Recording, and (3) Recovery.

In the following discussion, ``taking a sample'' means to record the attack
tool's output while Links loads one URL.

In the Training phase, the attacker takes $S$ samples of each URL. This must be
done on the victim's system with low system load. The attacker should be to do
this on an equivalent system that they control, but we have not confirmed this.

In the Victim Recording phase, the attacker records the attack tool's output
while the victim visits one of the URLs.

In the Recovery phase, the attacker computes the Levenshtein distance (edit
distance) between the victim sample and all of the training samples, finding the
sample with the least Levenshtein distance. The URL that produced this sample is
assumed to be the URL the user visited.

In an experiment on the top 100 most accessed Wikipedia pages of 2013
\cite{wikitop2013}, with $S=10$ and the victim visiting each page once, 91 of
the URLs were correctly recovered. With $S=5$, 76 of the URLs are correctly
recovered. This indicates that with 10 samples, the correct URL can be recovered
with 91\% accuracy. 

This does not completely follow from the experiments, however, since we are only
letting the victim run each URL once. To establish attack reliability, we need
to let the victim run each URL multiple times, and correctly recover it most of
the time. Without trying this, we have not ruled out pathological URLs that
cannot be distinguished (e.g.\ two pages that are very similar to each other).
Some preliminary results are known: With $S=2$ and the victim visiting each URL
10 times, all but one URL (``List of Breaking Bad Episodes'') are recovered
correctly at least once (the overall correctness for that experiment is 69.7\%).

We plan to run a full experiment with 10 samples of each URL, and having the
victim visit each URL 10 times. With the performance of the current
implementation, this will take about 4 days to run.

\section{Future Work}
\label{sec:future}

As noted above, we only ran part of the Links experiment. Next, we have to run
the full experiment. There are also improvements to be made to the TrueCrypt
attack. We are also need to measure and report on how long the attacks take to
perform.

For simplicity, experiments are run with the spy and victim processes running as
the same user. If the attacker were running as the same user, they could just
attach a debugger to the victim process. So, we have to re-run the experiments
with the processes separated.

The attacks presented above were hand-crafted. It took approximately a day of
work to find the best probe locations for the TrueCrypt probes. Links was chosen
because it was the first I was able to exploit out of Elinks, Firefox, Lynx, and
Links. To strengthen the argument that the FLUSH+RELOAD attack affects
non-cryptographic software, we should build a tool that automatically finds the
best probe locations. 

To start, we will try to automatically distinguish whether a program $P$ was run
with one of two inputs $I_1$ or $I_2$. The goal is to build a tool which will
take memory access recordings of $P$ running on $I_1$ and $I_2$, and find the
3 or 4 probe locations that best exhibit the differences.

We can reduce the amount of noise in the memory access recordings by recording
multiple samples, then taking the shortest ones (the ones with the least overall
number of memory accesses).

Once noise is reduced, we can model the problem as follows.

\textbf{Maximum-Stripped-LD}: Given an alphabet $\Sigma$ and strings $T_1, T_2
\in \Sigma^{*}$, find the set $P \subseteq \Sigma$ with $|P| \leq 4$ such that
The Levenshtein distance between $S_P(T_1)$ and $S_P(T_2)$ is maximal. Here,
$S_P(\omega) \in P^{*}$ denotes the string created by removing all characters
from $\omega$ that are not in $P$.

In this formalization, $\Sigma$ is the set of all cache lines in the code
segment of the program. $T_1$ and $T_2$ are the noise-reduced recordings of
which cache lines were accessed on inputs $I_1$ and $I_2$ respectively. The set
$P$ is to be the set of cache lines monitored by probes. We maximize the
Levenshtein distance since that is what the attack tool will use to distinguish
the inputs.

The obvious brute-force algorithm for \textbf{Maximum-Stripped-LD} takes
$O(n^6)$ time in the size of $\Sigma$ ($O(n^4)$ Levenshtein distance
computations, each of which take roughly $O(n^2)$ time). This is probably too
slow, so we may have to find a faster algorithm. Some early optimization ideas
are to (1) Collapse a run of $n$ of the same character down to just one
occurrence of that character, and (2) Remove the longest common substrings from
$T_1$ and $T_2$ (which most likely correspond to code that runs regardless of
what the input is).

Once the automatic probe locator is built, we can evaluate it by using it to
attack various applications. Some ideas follow:

\begin{itemize}
    \item Re-discover the TrueCrypt and Links attacks automatically.
    \item Determine when a message is being sent or received in Pidgin.
    \item Determine when a new email arrives, a mail filter is applied, is read,
          or is starred, in Thunderbird.
    \item Determine which of two GnuPG private keys were used to create
          a signature. A negative result will confirm that the original attacks
          against GnuPG are fixed. A positive result indicates some information
          about the key is still being leaked.
    \item Determine which of two functions are called in a PHP script.
    \item Determine whether a \texttt{SELECT} or \texttt{INSERT} query was
          executed against a database.
    \item Try to generalize the probe finder to distinguish $N$ inputs instead
          of just 2.
\end{itemize}

\section{Conclusion}
\label{sec:conclusion}

Side channel attacks exploit the boundary between the abstract notion of
a computer program and its real physical implementation. They use physical
measurements of time, power, vibrations, and radiation to learn what a computer
is doing. Most research has focused on applying these attacks to cryptographic
systems. We have shown that the FLUSH+RELOAD attack can be used against
non-cryptographic applications to compromise the user's privacy. Creating these
attacks requires manual effort, and we propose automating the process as the
next stage of this project.

\bibliographystyle{abbrv}
\bibliography{proposal}

\end{document}

